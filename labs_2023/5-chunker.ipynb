{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11c1974b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest2(target_word, embeddings, count=10):\n",
    "  cos_sim = []\n",
    "  target = embeddings[target_word]\n",
    "  target_len = np.sqrt(np.sum(target**2))\n",
    "  for word in embedded_words:\n",
    "    vec = embeddings[word]\n",
    "    dot = np.dot(vec, target)\n",
    "    vec_len = np.sqrt(np.sum(vec**2))\n",
    "    cos_sim.append((word,dot/(vec_len*target_len)))\n",
    "  cos_sim = sorted(cos_sim, key=lambda x: -x[1])[:count]\n",
    "  return[tup[0] for tup in cos_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        sentence_X = []\n",
    "        sentence_Y = []\n",
    "        for word in sentence:\n",
    "            if(tolower):\n",
    "                sentence_X.append(word[key_x].lower())    \n",
    "            else : \n",
    "                sentence_X.append(word[key_x])\n",
    "            sentence_Y.append(word[key_y])\n",
    "        X.append(sentence_X)\n",
    "        Y.append(sentence_Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = sorted(list(set(sum(X_train_symbs,[]))))\n",
    "chunks = sorted(list(set(sum(Y_train_symbs,[]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(embedded_words+words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {i+2:vocabulary_words[i] for i in range (len(vocabulary_words))}\n",
    "idx2chunk = {i+1:chunks[i] for i in range (len(chunks))}\n",
    "word2idx = {vocabulary_words[i]:i+2 for i in range (len(vocabulary_words))}\n",
    "chunk2idx = {chunks[i]:i+1 for i in range (len(chunks))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "temp = set(embedded_words)\n",
    "for word in vocabulary_words:\n",
    "  idx = word2idx[word]\n",
    "  if word in temp:\n",
    "    embedding_matrix[idx] = embeddings_dict[word]\n",
    "  else:\n",
    "    out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[w] for w in x])\n",
    "    Y_train_idx.append([chunk2idx[c] for c in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "'''\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, lstm_units, batch_first=True, bidirectional=bidi_lstm)\n",
    "             \n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.rnn(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n",
    "'''\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, lstm_units, nbr_classes, \n",
    "                 freeze_embs=True, num_layers=1, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        embedding_dim = embedding_matrix.size()[-1] \n",
    "        self.embeddings = nn.Embedding.from_pretrained(embedding_matrix, \n",
    "                                                       freeze=freeze_embs, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, num_layers=num_layers, \n",
    "                            dropout=0.2,\n",
    "                            batch_first=True, bidirectional=bidi_lstm)\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        embeds = self.dropout(embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_tensor = torch.tensor(embedding_matrix).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)\n",
    "model1 = Model(embedding_matrix, \n",
    "              LSTM_HIDDEN_DIM, \n",
    "              len(chunks) + 1, \n",
    "              freeze_embs=False, \n",
    "              num_layers=3, \n",
    "              bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (lstm): LSTM(100, 128, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:56<00:00,  4.99it/s]\n",
      "100%|██████████| 280/280 [00:56<00:00,  4.98it/s]\n",
      "100%|██████████| 280/280 [00:55<00:00,  5.01it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = torch.tensor([word2idx.get(word, 1) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes tensor([358640, 373606, 343335, 245002,      1,    873])\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.9189e-10, 1.5468e-06, 2.2005e-05, 9.8044e-12, 5.2110e-06, 2.3464e-07,\n",
       "        9.9909e-01, 2.3007e-08, 4.5547e-10, 9.5818e-07, 2.6241e-14, 7.9540e-08,\n",
       "        5.3120e-11, 1.2980e-07, 1.2786e-11, 2.0999e-12, 4.0932e-05, 3.3275e-09,\n",
       "        5.8255e-15, 2.8527e-09, 2.2405e-11, 1.8708e-09, 8.3654e-04],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(w,1) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-11.6122,  -8.6487,  -8.5492,  ..., -16.9548, -10.5442,  -1.6186],\n",
      "        [-11.6554,  -5.3769,  -5.8286,  ..., -15.2785,  -4.8302,  -2.5514],\n",
      "        [-10.8891,  -7.6982,  -5.9742,  ..., -19.4890,  -9.6020,  -2.3241],\n",
      "        ...,\n",
      "        [  8.9344, -13.1616, -13.9660,  ..., -37.8136, -27.5990,  -5.8672],\n",
      "        [  7.8935, -12.7808, -18.1974,  ..., -40.1930, -22.9501,  -9.0693],\n",
      "        [  8.2466, -12.8186, -13.4656,  ..., -38.1509, -20.9431,  -7.6875]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'lstm_3layers.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8950761041337437"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1268c1a30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest2(target_word, embeddings, count=10):\n",
    "  cos_sim = []\n",
    "  target = embeddings[target_word]\n",
    "  target_len = np.sqrt(np.sum(target**2))\n",
    "  for word in embedded_words:\n",
    "    vec = embeddings[word]\n",
    "    dot = np.dot(vec, target)\n",
    "    vec_len = np.sqrt(np.sum(vec**2))\n",
    "    cos_sim.append((word,dot/(vec_len*target_len)))\n",
    "  cos_sim = sorted(cos_sim, key=lambda x: -x[1])[:count]\n",
    "  return[tup[0] for tup in cos_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        sentence_X = []\n",
    "        sentence_Y = []\n",
    "        for word in sentence:\n",
    "            if(tolower):\n",
    "                sentence_X.append(word[key_x].lower())    \n",
    "            else : \n",
    "                sentence_X.append(word[key_x])\n",
    "            sentence_Y.append(word[key_y])\n",
    "        X.append(sentence_X)\n",
    "        Y.append(sentence_Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = sorted(list(set(sum(X_train_symbs,[]))))\n",
    "chunks = sorted(list(set(sum(Y_train_symbs,[]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(embedded_words+words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {i+2:vocabulary_words[i] for i in range (len(vocabulary_words))}\n",
    "idx2chunk = {i+1:chunks[i] for i in range (len(chunks))}\n",
    "word2idx = {vocabulary_words[i]:i+2 for i in range (len(vocabulary_words))}\n",
    "chunk2idx = {chunks[i]:i+1 for i in range (len(chunks))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "temp = set(embedded_words)\n",
    "for word in vocabulary_words:\n",
    "  idx = word2idx[word]\n",
    "  if word in temp:\n",
    "    embedding_matrix[idx] = embeddings_dict[word]\n",
    "  else:\n",
    "    out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    X_train_idx.append([word2idx[w] for w in x])\n",
    "    Y_train_idx.append([chunk2idx[c] for c in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "#\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, lstm_units, batch_first=True, bidirectional=bidi_lstm)\n",
    "        self.fc = nn.Linear(lstm_units*2, nbr_classes)\n",
    "\n",
    "        '''\n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "        '''\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.rnn(embeds)\n",
    "        #lstm_out = F.relu(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (rnn): RNN(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:03<00:00, 70.89it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 59.98it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.89it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 59.05it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.73it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.59it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 57.94it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.50it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 57.89it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 57.50it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.76it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.70it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.55it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 58.52it/s]\n",
      "100%|██████████| 280/280 [00:04<00:00, 59.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = torch.tensor([word2idx.get(word, 1) for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes tensor([358640, 373606, 343335, 245002,      1,    873])\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = model1(sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4506e-12, 4.9493e-06, 1.1142e-05, 1.0078e-08, 3.7115e-07, 3.3063e-08,\n",
       "        9.9925e-01, 2.3545e-05, 3.3034e-08, 2.9305e-06, 8.2466e-16, 2.6713e-08,\n",
       "        3.2877e-08, 6.5460e-09, 2.9189e-09, 1.1416e-10, 2.2549e-05, 1.9885e-08,\n",
       "        2.3504e-13, 1.4594e-09, 1.1939e-09, 6.7622e-09, 6.8242e-04],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    X_test_idx.append([word2idx.get(w,1) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-15.2910,  -4.3374,  -7.4815,  ...,  -7.1774,  -5.8940,  -1.0863],\n",
      "        [-18.7412,  -7.8045,  -3.5604,  ...,  -8.7941,  -2.7141,   0.3402],\n",
      "        [-22.5962,  -5.1484,  -5.9322,  ..., -13.2512, -10.5556,  -0.8601],\n",
      "        ...,\n",
      "        [ -8.5171,  -2.0130,  -4.2775,  ..., -10.6650,  -4.5676,   4.3702],\n",
      "        [ -7.3477,  -1.5135,  -4.1512,  ..., -10.0127,  -4.5048,   3.9205],\n",
      "        [ -6.4240,  -1.1470,  -4.0654,  ...,  -9.4653,  -4.5011,   3.6063]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962503938661905"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
